{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\"\"\"Generate trees.\n",
    "\n",
    "* @File    :   6_generate_trees.ipynb\n",
    "* @Time    :   2025/04/01 19:20:19\n",
    "* @Author  :   Marc Ballestero RibÃ³\n",
    "* @Version :   0\n",
    "* @Contact :   marcballesteroribo@gmail.com\n",
    "* @License :   MIT\n",
    "* @Desc    :   None\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Generate Trees\n",
    "\n",
    "This notebook, part of the analysis phase of the project, is devoted to generating the constituency trees that will later be fed to Integrated Directional Gradients (IDG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 09:33:22.599469: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-07 09:33:22.663571: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-07 09:33:22.676689: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-07 09:33:22.682106: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-07 09:33:22.752852: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Necessary imports\n",
    "import polars as pl\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.auto import tqdm as tqdma\n",
    "\n",
    "import stanza\n",
    "\n",
    "# Get the absolute path of the project's root directory\n",
    "ROOT_DIR = Path.resolve(Path.cwd() / \"../\")\n",
    "\n",
    "# Add root directory to sys.path\n",
    "sys.path.append(str(ROOT_DIR))\n",
    "\n",
    "from src.utils.set_seed import set_seed\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "rng = set_seed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory management\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "SPLITTED_DATA_DIR = DATA_DIR / \"splitted\"\n",
    "\n",
    "MODELS_DIR = ROOT_DIR / \"models\"\n",
    "\n",
    "OUTPUT_DIR = ROOT_DIR / \"output\"\n",
    "TREES_DIR = OUTPUT_DIR / \"constituency_trees\"\n",
    "IDG_DIR = OUTPUT_DIR / \"integrated_directional_gradients\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and process the HateXplain Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframe\n",
    "df_test = pl.read_parquet(SPLITTED_DATA_DIR / \"test_2_classes.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "label2id = {\"normal\": 0, \"hatespeech\": 1}\n",
    "id2label = {id_: label for label, id_ in label2id.items()}\n",
    "target_labels = list(label2id.keys())\n",
    "\n",
    "df_test = df_test.with_columns(\n",
    "    pl.col(\"label\").replace_strict(label2id),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate the constituency trees for the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree(\n",
    "    nlp_pipeline: stanza.Pipeline,\n",
    "    sentence: str,\n",
    ") -> str:\n",
    "    \"\"\"Generate the constituency tree for a given sentence, process it and return it as a string.\n",
    "\n",
    "    Args:\n",
    "        nlp_pipeline (stanza.Pipeline): The Stanza NLP pipeline for processing the sentence.\n",
    "        sentence (str): The input sentence for which the constituency tree is to be generated.\n",
    "\n",
    "    Returns:\n",
    "        str: The constituency tree of the sentence as a string.\n",
    "\n",
    "    \"\"\"\n",
    "    # Process the sentence\n",
    "    doc = nlp_pipeline(sentence)\n",
    "\n",
    "    # Extract the constituency tree\n",
    "    constituency_tree = doc.sentences[0].constituency\n",
    "\n",
    "    # Remove the root node\n",
    "    constituency_tree = constituency_tree.children[0]\n",
    "\n",
    "    return str(constituency_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 09:33:24 INFO: Loading these models for language: en (English):\n",
      "======================================\n",
      "| Processor    | Package             |\n",
      "--------------------------------------\n",
      "| tokenize     | combined            |\n",
      "| pos          | combined_charlm     |\n",
      "| constituency | ptb3-revised_charlm |\n",
      "======================================\n",
      "\n",
      "2025-04-07 09:33:24 INFO: Using device: cuda\n",
      "2025-04-07 09:33:24 INFO: Loading: tokenize\n",
      "2025-04-07 09:33:24 INFO: Loading: pos\n",
      "2025-04-07 09:33:26 INFO: Loading: constituency\n",
      "2025-04-07 09:33:26 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Create a `stanza` pipeline for tokenization and constituency tree extraction\n",
    "nlp = stanza.Pipeline(\n",
    "    lang=\"en\",\n",
    "    processors=\"tokenize,pos,constituency\",\n",
    "    use_gpu=True,\n",
    "    package=\"default\",\n",
    "    tokenize_pretokenized=True,\n",
    "    download_method=None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5214302f900455bb4fb44ca91707a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating trees:   0%|          | 0/1376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate trees with tqdm progress bar\n",
    "trees = [\n",
    "    generate_tree(nlp, \" \".join(tokens)) for tokens in tqdma(df_test[\"tokens\"], desc=\"Generating trees\")\n",
    "]\n",
    "\n",
    "# Add the new column to the DataFrame\n",
    "df_test = df_test.with_columns(pl.Series(\"tree\", trees))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame with the new column\n",
    "df_test.write_parquet(TREES_DIR / \"test_2_classes_with_trees.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscthesisdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
